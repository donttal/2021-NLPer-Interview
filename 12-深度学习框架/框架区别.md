[toc]

## 1——动态及静态图形定义

两种框架都在张量上运行，把任何模型都看作一个有向非循环图（DAG），但对于如何定义它们，PyTorch 和 TensorFlow 区别很大。


TensorFlow 遵循“数据即是代码，代码就是数据”的理念。在 TensorFlow 中，在跑模型之前会静态的定义图形。和外界的所有联系都是通过 tf.Session 对象和 tf.Placeholder，它们都是会在模型运行被外部数据取代的张量。


在 PyTorch 中，会更动态一些：你可以随着进展定义、更改和执行节点，没有特殊的会话界面或占位符。整体来看，PyTorch 和 Python 结合的更紧凑些，多数时候会感觉更原生。而在 TensorFlow 里写东西时，有时你会觉得你的模型好像躲在一堵墙后面一样，就通过墙上的几个洞洞跟你交流。当然了，这也看每个人的喜好和品味。


不过，不单单是在软件工程方面有区别，一些动态神经网络架构可以从这种动态方法种受益。回想一下循环神经网络：有静态图形，输入序列长度会保持不变。这意味着如果你开发一个应用于英语句子的情绪分析模型，就必须将序列长度修正为某些最大值，用 0 填补所有较小的序列。这比较麻烦吧。在递归循环神经网络和树形循环神经网络方面，你会遇到更多问题。

**目前，TensorFlow 对于动态输入的支持比较有限，而 PyTorch 则是默认的支持动态输入。**

## 2- 可视化

在可视化方面，TensorFlow 的 Tensorboard 是个非常棒的功能。它内置在 TensorFlow 中，在调试和比较不同的训练状况时非常有用。例如，假设你训练了一个模型，然后调整一些超参数后又训练一次。而在 Tensorboard 上可以将这两次模型运行状况同时展现出来，从而看出两次的差异。Tensorboard 可以：

* 展示模型图形
* 绘制标量变量
* 可视化分布和直方图
* 可视化图形
* 播放音频

Tensorboard 可以展示多种总结，通过 tf.summary 模块就可以收集到。我们可以为前面的指数例子定义总结操作，用 tf.summary.FileWriter 将它们保存到桌面。


执行 tensorboard --logdir=./tensorboard 就可启动 Tensorboard。由于它是 web 应用，因此可以很方便的用在云实例上。


目前 PyTorch 并没有可以和 Tensorboard 匹敌的工具，不过倒是存在一些集成功能。虽然也能用一些绘图工具比如 matplotlib 和 seaborn，但在可视化这方面，PyTorch 要逊于 TensorFlow。

## 3——部署

在部署这方面，TensorFlow 很明显目前略胜一筹：其内置框架 TensorFlow Serving 能让你在特制的 gPRC 服务器上部署你的模型。也同样支持移动端。


在 PyTorch 上，我们就需要用 Flask 或其它工具在模型上编写一个 REST API。在使用 TensorFlow 的时候，如果 gPRC 不是很适用，我们同样可以这么做。不过，如果考虑性能的话，TensorFlow Serving 会是更好的选择。


TensorFlow 同样支持分布式训练，这点 PyTorch 目前尚不具备。


## 4—— 数据并行

PyTorch 不同于 TensorFlow 的最大特性之一就是声明式数据并行：你可以用 torch.nn.DataParellel 封装任何模型，而且模型能在批处理维度上实现并行。这样你就可以毫不费力的使用多个 GPU。


另一方面，TensorFlow 能让你调试在具体设备上运行的所有操作。不过，数据并行不仅需要手动调整，还需要深思熟虑。