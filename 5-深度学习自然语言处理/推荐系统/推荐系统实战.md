# 推荐系统实战
[推荐系统学习路线](https://www.zhihu.com/question/23194692)

## 推荐系统类型
* 主页推荐，主页推荐是基于用户已知兴趣的个性化推荐，每个用户看到的推荐列表是不同的
* 相关条目推荐，对特定条目的相似推荐

### 术语
**条目（Item）**
推荐系统的实体。 对于淘宝来说，这些条目是用户要购买的商品。 对于抖音，这些条目是视频。
**查询（Query）**
推荐系统用以给出推荐的相关信息，查询可以是以下各项的组合：
用户信息：用户的ID，用户先前与之产生交互的条目
上下文信息：一天中的时间，用户的设备
条目信息：商品名称，商品类别
**嵌入（Embedding）**
从离散集合（查询集或要推荐的条目）到嵌入（Embedding）空间的向量空间映射。 许多推荐系统都依赖于学习查询和项目的合理嵌入（Embedding）表示。

### 推荐系统架构
推荐系统的一种通用体系架构由三部分组成：召回、打分、重排

**召回（粗排）**
在此第一阶段，系统从潜在的庞大语料库开始，并生成更小的候选集。例如，抖音中的召回将从数十亿个视频中选出数百或数千个。考虑到语料库的庞大规模，该模型需要快速评估查询。给定模型可以有多个召回队列，每个召回队列都筛选出不同类型的候选子集。

**计分（精排）**
接下来，另一个模型对候选集进行评分和排序，以选择要显示给用户的集合（大约10个）。由于此模型评估的是商品的相对较小子集，因此系统可以依靠其他信息来使用更精确的模型。

**重排（调序）**
最后，系统必须考虑最终排名的其他限制。例如，系统删除用户明确不喜欢的项目或提高时效内容的得分。重新排序还可以帮助确保多样性，时效性和公平性。

# 召回概述

召回是推荐系统的第一阶段。 给定query，系统将生成相关的候选集合。 下面介绍两种常见的召回方法：

- **基于内容的过滤**：使用item之间的相似性来推荐与用户喜欢的item相似的item。

> 例如：如果用户A观看了两个可爱的猫视频，则系统可以向该用户推荐可爱的动物视频。

- **协同过滤**：同时使用query和item之间的相似性来进行推荐。

> 例如：如果用户A与用户B类似，并且用户B喜欢视频1，则系统可以向用户A推荐视频1（即使用户A尚未看过任何与视频1类似的视频）。

- **基于神经网络的方法：**利用神经网络生成相应的候选集。

## 向量空间

基于内容的过滤和协同过滤都将每个item和每个query（或上下文）映射到公共Embedding空间中的Embedding向量$E=\mathbb{R}^{d}$。 通常，Embedding空间是低维的（即$d$) 比语料库的大小小得多），用以表示item或query的某些潜在含义。 相似item（例如通常由同一用户观看的YouTube视频）最终在Embedding空间中拥有相近的表示。 “相似性”的概念由相似性度量定义。

## 相似性度量

相似性度量是一个函数$s: \quad E \times E \rightarrow \mathbb{R}$ 它的输入是一对Embedding并返回一个标量，以度量它们的相似性。 Embedding可用于召回，如下所示：给定query Embedding $q \in E$ 后，推荐系统会查找相近$s(q, x)$（即，具有高度相似性的Embedding）的Item Embedding $x \in E$
为了确定相似程度，大多数推荐系统都依赖以下一项或多项的相似计算方法：

> 余弦（cosine）
> 点积（dot product）
> 欧氏距离（Euclidean distance）

**余弦：**即两个向量之间夹角的余弦， $s(q, x)=\cos (q, x)$

**点积：**两个向量的点积为$s(q, x)=<q, x>=\Sigma_{i=1}^{d} q_{i} x_{i}$ 因此，如果将Embedding归一化，则点积和余弦是相等的。

**欧式距离：**这是欧几里得空间中的通常距离，$s(q, x)=\|q-x\|=\sqrt{\sum_{i=1}^{d}\left(q_{i}-x_{i}\right)^{2}}$。 较小的距离意味着较高的相似性。 请注意，在对Embedding进行归一化时，平方欧氏距离与点积（和余弦）重合，是一个常数，因为在这种情况下$\frac{1}{2}\|q-x\|^{2}=1-<q, x>$。

## 相似度比较

考虑下图中的示例。 黑色矢量说明了query Embedding。 其他三个Embedding向量（item A，item B，item C）表示候选集合。 根据所使用的相似性度量，item的排名可能会有所不同。

![img](https://pic3.zhimg.com/80/v2-40c5629a4e0334b9961c3fd76b0722ba_hd.jpg)

## 选择哪种相似性度量方式？

与余弦相比，点积相似度对Embedding的范数更敏感。即，Embedding的范数越大，相似度越高（对于具有锐角的item），并且越可能推荐该item。这可能会影响推荐系统，如下所示：

- 训练集中经常出现的item（例如，受欢迎的视频）往往具有较大的范数embedding。如果需要刻画相应的流行度信息，那么点积是不错的计算方式。但是，如果使用不小心，推荐出来的内容可能全部都是流行的内容（被过度放大）。在实践中，您可以使用相似性度量的其他变体，这些变体可以弱化item范数的影响。例如， ![[公式]](https://www.zhihu.com/equation?tex=s%28q%2Cx%29+%3D+%5Cleft%5C%7Cx%5Cright%5C%7C%5E%5Calpha+%5Cleft%5C%7Cq%5Cright%5C%7C%5E%5Calpha+cos%28q%2Cx%29+%2C++%5Calpha%5Cin%280%2C1%29) 。
- 在训练时，很少出现的item不会经常更新。因此，如果使用大范数对它们进行初始化，则系统可能会推荐较少出现的item，而不是更相关的item。为避免此问题，请注意Embedding的初始化，并使用适当的正则化。

------

## 基于内容的过滤

根据用户先前的操作或明确的反馈(例如点击，评论等)，基于内容的过滤使用item相关特征来推荐给用户与之前喜欢的item类似的item。

为了更形象的表示基于内容的过滤，假设一个应用商店要推荐给用户相应的APP。下图是相应的特征矩阵，其中每一行代表一个应用程序，每一列代表一个特征。包括不同的类别特征（例如，Education, Casual, Health），应用程序的发布者信息等。为简化起见，假定此特征矩阵是布尔类型的的：非零值表示应用程序具有该特征。

还可以在同一特征空间中表示用户。一些与用户相关的特征可以由用户明确提供。例如，用户在其个人资料中选择“娱乐应用”。其他特征可能是隐式的，具体取决于它们先前安装的应用程序。

模型应推荐与此用户有关的item。为此，必须首先选择一个相似性指标（例如，点积）。然后，推荐系统会根据此相似性度量标准为每个候选item打分。请注意，建议是针对该用户的，因为该模型未使用其他用户的任何信息。

![img](https://pic4.zhimg.com/80/v2-8cc83410cf02682b0aa030c746bb501b_hd.jpg)

**基于内容过滤的优点**

- 该模型不需要其他用户的任何数据，因为推荐是针对该用户的。 这使得更容易扩展到大量用户。
- 该模型可以捕获用户的特定兴趣，并可以推荐其他用户很少感兴趣的但该用户喜欢的item。

**基于内容过滤的缺点**

**- 由于item的特征表示在某种程度上是手工设计的，因此该技术需要大量领域知识。 因此，模型很依赖手工设计特征的好坏。
- 该模型只能根据用户的现有兴趣提出建议。 换句话说，该模型扩展用户现有兴趣的能力有限。**

------

## 协同过滤

为了解决基于内容的过滤的某些问题，协同过滤同时使用用户和item之间的相似性来进行推荐。 这样可以提高模型的推荐拓展性。也就是说，协同过滤模型可以根据相似用户B的兴趣向用户A推荐商品。此外，可以自动学习Embedding，而无需依赖手工设计的特征。

## 一个电影推荐系统的例子

考虑一个电影推荐系统，其中训练数据由一个反馈矩阵组成，其中：

- 每行代表一个用户
- 每列代表一个item（电影）

关于电影的反馈分为以下两类：

- 显示反馈：用户通过提供数字评分来指定他们对特定电影的喜欢程度。
- 隐式反馈：如果用户观看电影，则系统会推断用户感兴趣。

为简化起见，我们假设反馈矩阵是布尔类型的。 即，值为1表示对电影感兴趣。

用户访问首页时，系统应根据以下两种情况推荐电影：

- 与用户过去喜欢的电影相似
- 类似用户喜欢的电影

为便于举例阐述，让我们手工设计用以描述电影的一些特征：

![img](https://pic2.zhimg.com/80/v2-4301604c1b02d92da969d35699c4f045_hd.jpg)

**一维Embedding**

假设我们为每部电影分配一个标量，用于描述该电影是适合儿童（负值）还是适合成人（正值）观看。 假设我们还为每个用户分配了一个标量，用于描述用户对儿童电影（接近-1）或成人电影（接近+1）的兴趣。 对于我们希望用户喜欢的电影，电影Embedding和用户Embedding的乘积应更高（接近1）。

![img](https://pic2.zhimg.com/80/v2-fbbd0c301746c9b545c061da24e2470d_hd.jpg)

在下图中，每个对号标记都标识特定用户观看的电影。 第三和第四用户具有的特征很好地表示了用户的偏好：第三用户偏爱儿童电影，第四用户偏爱成人电影。 但是，单个特征无法很好地表示第一和第二用户的偏好。

**二维Embedding**

一个特征不足以解释所有用户的偏好。 为了克服这个问题，让我们添加第二个特征：每部电影是商业流行片或是小众文艺片上的表现程度。 通过这个特征，我们现在可以使用以下二维Embedding来表示每部电影：

![img](https://pic2.zhimg.com/80/v2-028bc734d4943ef1ca47243afa4fe625_hd.jpg)

我们再次将用户放置在相同的嵌入空间中，以最好地解释反馈矩阵：对于（用户，商品）对，我们希望用户Embedding和商品Embedding的点积在用户观看商品时接近1 电影，否则为0。

![img](https://pic2.zhimg.com/80/v2-8f2351cf206f54faea50493373b7a299_hd.jpg)

在这个例子中，我们对Embedding进行了手工设计。 在实践中，可以自动学习Embedding，这是协同过滤模型的强大功能。 在接下来的内容中，我们将讨论学习这些嵌入的不同模型以及如何对其进行训练。

当模型自动学习Embedding时，这种方法的协同性质就显而易见了。 假设电影的Embedding矢量是固定的。 然后，模型可以为用户学习Embedding向量，以最好地解释他们的偏好。 因此，具有相似偏好的用户的Embedding将紧密在一起。 同样，如果用户的Embedding是固定的，则我们可以学习电影Embedding以最好地解释反馈矩阵。 结果，类似用户喜欢的电影的Embedding将在Embedding空间中紧密在一起。

## 矩阵分解

矩阵分解是一个简单的Embedding模型。 给定反馈矩阵 $A \in R^{m \times n}$ ，其中 $m$是用户（或query）数量， $n$是item数量，该模型将学习：

- 用户Embedding矩阵 $U \in \mathbb{R}^{m \times d}$ ，其中第i行是用户i的Embedding。
- item Embedding矩阵 $V \in \mathbb{R}^{n \times d}$，其中第j行是item j的Embedding。

![img](https://pic3.zhimg.com/80/v2-b04444f1c920309f99f5e2245b82aa96_hd.jpg)

Embedding通过学习，使得$U V^{T}$的乘积是反馈矩阵$A$的良好近似。 $U V^{T}$的$(i, j)$项就是user $i$ 和item $j$ 对应的两个embedding的点积，使其尽量接近$A_{i, j}$
> 注意：与学习完整矩阵相比，矩阵分解通常会得到更简洁的表示。 完整矩阵具有$O(n m)$项，而Embedding矩阵具有$O((n+m) \times d)$项，其中Embedding维数$d$通常比 $m$ 和 $n$ 小得多。 最终，观测矩阵会被映射到低维子空间中，矩阵分解就可以在数据中找到其对应的潜在信息。在现实世界中的推荐系统中，矩阵分解可以比学习整个矩阵要简洁得多。

## 选择目标函数

一种直观的目标函数是距离的平方， 即在所有观察到的矩阵项上最小化平方误差之和：

![img](https://pic3.zhimg.com/80/v2-1a513b3821037e7c37e292f392904e7e_hd.jpg)

在此目标函数中，只求观察到的对 ![[公式]](https://www.zhihu.com/equation?tex=%28i%2Cj%29) 的误差和，即对反馈矩阵中的**非零值**求和。 但是，只求1的误差总和并不是一个好方法。最小化矩阵中所有为1元素产生的模型，并不能进行很好的推荐，而且泛化性较差。

![img](https://pic2.zhimg.com/80/v2-21fd6f0ca884f39bc86128bd076c56fd_hd.jpg)

也许可以将未观察到的值视为零，并对矩阵中的所有条目求损失和。这样其实就是最小化 ![[公式]](https://www.zhihu.com/equation?tex=A) 及其近似值 ![[公式]](https://www.zhihu.com/equation?tex=UV%5ET) 之间Frobenius距离的平方：

![img](https://pic3.zhimg.com/80/v2-873e1d22ea57e8af3b17bb1d393c11ee_hd.jpg)

可以通过矩阵的奇异值分解（SVD）解决此二次问题。 但是，SVD并不是一个很好的解决方案，因为在实际应用中，矩阵 ![[公式]](https://www.zhihu.com/equation?tex=A) 可能非常稀疏。 例如，将抖音上所有视频与特定用户观看过的视频进行比较。 得到的解 ![[公式]](https://www.zhihu.com/equation?tex=UV%5ET) （对应于模型对输入矩阵的近似值）可能接近于零，从而导致泛化性能较差。

相比之下，加权矩阵分解将目标分解为以下两部分的和：

- 观察到的误差和
- 未观察到的误差和（视作0）

![img](https://pic3.zhimg.com/80/v2-123e2461f899343682d8baf2b534de8e_hd.png)

**$w_0$ 是调节两项加权的超参，以使目标不被其中一项所支配。 调整此超参数非常重要。**

在实际应用中，您还需要仔细权衡观察到的数据。 例如，频繁的item（例如，非常受欢迎的视频）或频繁的query（例如，重度用户）可能会主导目标功能。 可以通过对频繁出现的item所对应的训练样本进行加权来纠正此影响。 换句话说，您可以将目标函数替换为：

![img](https://pic2.zhimg.com/80/v2-ecf192ed838f811c9d701c1ebf01501d_hd.png)

$w_{i, j}$ 是query$i$ 和item $j$ 对应的频率函数。

## 最小化目标函数

最小化目标函数的常用算法包括：

- **随机梯度下降（SGD）**是使损失函数最小化的通用方法。
- **加权交替最小二乘（WALS）**专用于此特定目标函数。

在两个矩阵U和V中，每个目标都是二次的。（但是，请注意，联合问题并不是凸的。）WALS的工作方式是随机初始化Embedding，然后在以下条件之间交替进行：

- 固定 ![[公式]](https://www.zhihu.com/equation?tex=U) 求解 ![[公式]](https://www.zhihu.com/equation?tex=V) 。
- 固定 ![[公式]](https://www.zhihu.com/equation?tex=V) 求解 ![[公式]](https://www.zhihu.com/equation?tex=U) 。

每步都可以准确地求解（通过线性问题的解决方法）并可以进行分布式计算。 该技术可以保证收敛，因为可以确保每一步都可以减少损失。

## SGD vs. WALS

SGD和WALS具有优点和缺点。 下文是对它们的比较：

**SGD优点**

- 非常灵活：适用于其他损失函数。
- 可以并行化。

**SGD缺点**

较慢：收敛速度不那么快。

难以处理未观察到的项（entries），需要使用负采样或gravity。

**WALS优点**

可以并行化。

收敛速度比SGD更快。

更容易处理未观察到的项（entries）。

**WALS缺点**

仅适用于平方损失。

## 协同过滤的优点和缺点

**优点**

- **无需领域知识**：不需要相关领域知识，因为Embedding是自动学习的。
- **发掘用户兴趣**：该模型可以帮助用户发现新兴趣。 孤立地，ML系统可能不知道用户对给定的item感兴趣，但是模型可能仍会推荐它，因为相似的用户对该item感兴趣。
- **很好的初始模型**：在某种程度上，该方法仅需要反馈矩阵即可训练矩阵分解模型。 特别是，该方法不需要上下文特征。 实际上，这可以用作多个召回队列中的一个。

**缺点**

**冷启动问题**

模型预测结果是给定的（用户，商品）相应Embedding的点积。因此，如果在训练数据中item未出现，则系统将无法为其创建Embedding，也无法得到相应的预测结果。此问题通常称为冷启动问题。但是，以下技术可以在某种程度上解决冷启动问题：

> **1.利用WALS进行预测**。给定一个在训练集中未出现的item，如果系统与用户有一些交互，则系统可以轻松计算出该item的Embedding，而无需重新训练整个模型。系统只需解决以下方程式或其加权形式：

![img](https://pic3.zhimg.com/80/v2-1e0380ad04598b651131653f8c23de3e_hd.jpg)

> 上述方程对应于WALS中的一个迭代：用户Embedding保持固定，系统求解item的Embedding。对于新用户也可以这样做。
> **2.启发式生成新item的Embedding**。如果系统没有相应的交互信息，则系统可以通过对来自同一类别，来自同一上传者（在视频推荐中）的item的Embedding进行平均来近似其嵌入。

**难以融入query/item的附加特征**

附加特征是query或itemID以外的其他特征。 对于电影推荐，附加特征可能包括国家或年龄。 融入可用的附加特征可以提高模型的效果。 尽管在WALS中融入付诸特征可能并不容易，但是WALS的泛化模型使这成为可能。

对于泛化WALS模型，通过定义block矩阵来增加特征的输入矩阵，其中：

- 块（0，0）是原始反馈矩阵 ![[公式]](https://www.zhihu.com/equation?tex=A) 。
- 块（0，1）是user特征的muti-hot编码。
- 块（1，0）是item特征的muti-hot编码。

> 注意：块（1，1）通常留空。 如果对A的block矩阵进行矩阵分解，则除了user和item Embedding之外，系统还会学习附加特征的Embedding。

------

## 深度神经网络模型

前文讲述了如何使用矩阵分解来学习Embedding。 矩阵分解的一些限制包括：

- 使用附加特征（即queryID /itemID以外的其他特征）困难。 因此只能对训练集中存在的用户或item进行推荐。
- 推荐的相关性。 正如前文所描述的那样，倾向于向所有人推荐热门item，尤其是在使用点积作为相似性度量时。 难以刻画特定的用户兴趣。

深度神经网络（DNN）模型可以解决矩阵分解的这些限制。 DNN可以轻松地融入query特征和item特征（由于网络输入层的灵活性），这可以帮助捕获用户的特定兴趣并提高推荐的相关性。

## 用以推荐的 Softmax DNN 模型

一种可能的DNN模型是利用softmax作为最后一层的输出，它会将问题视为多分类问题，其中：

- 输入是用户query。
- 输出是一个概率向量，其大小等于语料库中item的数量，代表与每个item进行交互的概率； 例如，点击或观看视频的可能性。

**输入**

DNN的输入可以包括：

- 稠密(dense)特征（例如，观看时间和自上次观看以来的时间）
- 稀疏(sparse)特征（例如观看历史和国家/地区）

与矩阵分解方法不同，可以添加年龄或国家/地区等附加特征。 我们用x表示输入向量。

![img](https://pic3.zhimg.com/80/v2-2be2361c2c24c92a8a406b4a1a570676_hd.jpg)

**模型结构**

模型结构决定了模型的复杂性和表达性。 通过添加隐层和非线性激活函数（例如ReLU），模型可以捕获数据中更复杂的关系。 但是，增加参数的数量通常也会使模型更难训练且服务成本更高。 我们将用$\psi(x) \in \mathbb{R}^{d}$表示最后一个隐藏层的输出。

![img](https://pic2.zhimg.com/80/v2-c614d0055ac37cc7f5e3b7bf3bd56b45_hd.jpg)

**输出:预测的概率分布**

该模型通过softmax层将最后一层的输出映射到概率分布 $\hat{p}=h\left(\psi(x) V^{T}\right)$，

![img](https://pic3.zhimg.com/80/v2-56fa86cc8c546c8a8f39a582dd1787aa_hd.jpg)

**损失函数**

最后，定义用以比较以下两项的损失函数：

- ![[公式]](https://www.zhihu.com/equation?tex=+%5Chat%7Bp%7D+) ，softmax层的输出（概率分布）
- ![[公式]](https://www.zhihu.com/equation?tex=p) ，groud-truth，代表用户与之互动的item（例如，用户点击或观看的视频）。 这可以表示为归一化的muti-hot分布（概率向量）。

例如，可以使用交叉熵损失来比较两个概率分布。

**Softmax Embedding**

item j 的概率由$\hat{p}_{j}=\frac{\exp \left(\left\langle\psi(x), V_{j}\right\rangle\right)}{Z}$给出，其中 $Z$ 是不依赖于 $j$ 的归一化常数。

换句话说,$\log \left(\hat{p}_{j}\right)=\left\langle\psi(x), V_{j}\right\rangle-\log (Z)$，因此，item $j$ 的对数概率是（最大为加法常数）两个 $d$ 维矢量的点积，可以将其解释为query和item Embedding：

- $\psi(x) \in \mathbb{R}^{D}$是最后一个隐藏层的输出。 我们称其为query 的Embedding。
- $V_{j} \in \mathbb{R}^{D}$是将最后一个隐藏层连接到输出j的权重向量。 我们称其为item的Embedding。

![img](https://pic3.zhimg.com/80/v2-85f510691d74a0b6c45bece163b6b45a_hd.jpg)

## DNN和矩阵分解

在softmax模型和矩阵分解模型中，系统对于每个item学习一个Embedding向量$V_{j}$。 我们在矩阵分解中所谓的item Embedding 矩阵$V \in \mathbb{R}^{n \times d}$现在是softmax层的权重矩阵。

但是，query Embedding是不同的。 系统不再对每个query学习一个对应的query Embedding向量，而是学习从query 特征 $x$ 到Embedding的映射$\psi(x) \in \mathbb{R}^{D}$。 因此，您可以将此DNN模型视为矩阵分解的泛化，其中将query侧替换为非线性函数$\psi(\cdot)m$。

## 可以使用item特征吗？

可以将相同的想法应用于item侧吗？ 也就是说，除了对每个item学习一个对应的Embedding之外，模型可以学习将item特征映射到Embedding的非线性函数吗？ 当然可以。 可以使用由两个神经网络组成的双塔模型：

- 一种神经网络将qeury特征 $x_{q u e r y}$ 映射到qeury Embedding ![[公式]](https://www.zhihu.com/equation?tex=+%5Cpsi%28x_%7Bquery%7D%29+%5Cin+%5Cmathbb%7BR%7D%5ED)
- 一个神经网络将item特征 ![[公式]](https://www.zhihu.com/equation?tex=x_%7Bitem%7D) 映射到item Embedding ![[公式]](https://www.zhihu.com/equation?tex=%5Cphi%28x_%7Bitem%7D%29+%5Cin+%5Cmathbb%7BR%7D%5ED)

模型的输出可以定义为 ![[公式]](https://www.zhihu.com/equation?tex=%5Cleft+%5Clangle+%5Cpsi%28x_%7Bquery%7D%29+%5Cphi%28x_%7Bitem%7D%29+%5Cright+%5Crangle+) 的点积。 请注意，这再是softmax模型。 新模型对每对 ![[公式]](https://www.zhihu.com/equation?tex=%28x_%7Bquery%7D%2Cx_%7Bitem%7D%29+) 预测一个值，而不是每个query的概率向量。

## 模型训练

前文解释了如何将softmax层合并到推荐系统的深度神经网络中。 下面介绍如何利用训练数据对模型参数进行求解。

**训练数据**

训练数据由query特征 ![[公式]](https://www.zhihu.com/equation?tex=x) 和与用户进行交互的item向量组成（表示为概率分布 ![[公式]](https://www.zhihu.com/equation?tex=p) ）。在下图中，标记为蓝色。 模型的变量是不同层中的权重。 在下图中，标记为橙色。 通常使用随机梯度下降相关方法来训练模型。

![img](https://pic1.zhimg.com/80/v2-480e71a0f20ddfb006b7a72a47b7bd54_hd.jpg)

**负采样**

由于损失函数会比较两个概率向量 ![[公式]](https://www.zhihu.com/equation?tex=p%2C%5Chat+p%28x%29+%5Cin+%5Cmathbb%7BR%7D%5En) （分别是ground-truth和模型的输出），因此如果语料库很大，梯度的损失（对于单个query ![[公式]](https://www.zhihu.com/equation?tex=x) ）可能会难以计算。

可以设置一个仅计算正例的梯度的模型。 但是，如果系统仅在正例上训练，模型可能会**折叠（folding）**，如下文所述。

在下图中，假设每种颜色代表不同类别的query和item。 每个query（表示为正方形）仅与相同颜色的item（表示为圆圈）进行交互。 例如，在视频网站中将每个类别都视为一种不同的语言。 典型的用户通常会与一种指定语言的视频进行互动。

![img](https://pic1.zhimg.com/80/v2-a02b16b4307a07f3443e74c520df9e00_hd.jpg)

该模型可以学习如何将给定颜色的query/item 进行Embedding（正确地刻画该颜色内的相似性），但是不同颜色的Embedding可能偶然出现在Embedding空间的同一区域中。 这种现象称为折叠，可能给出错误的推荐：在给出推荐item时，模型可能会错误地将不同组的商品预测出较高的分数。

**负例**是至与给定查询“无关”的item。 模型在训练过程中加入负例，可以教给该模型不同群体的Embedding应相互远离。

可以使用**负采样**来代替使用所有item来计算梯度（这可能难以计算）或仅使用正例（这会使模型发生折叠）。 更准确地说，可以使用以下item来计算近似梯度：

- 所有的正例（出现在目标label中的item）
- 采样后的负例

有多种负采样策略：

- 可以统一进行采样。
- 可以给得分更高的item以更高的采样概率。 直观地讲，这些是对梯度影响最大的item。 这些样本通常被称为hard negatives。

## 矩阵分解 Vs. 神经网络

DNN模型解决了矩阵分解的许多限制，但训练和预测开销更大。 下表总结了两种模型之间的一些重要区别。

![img](https://pic2.zhimg.33224 同样，DNN模型折叠（folding）通常是可以接受的，因为通常是在假定相关的预过滤候选集上进行排名。

# 检索
在服务时，给定查询，首先要执行以下操作之一：
- 对于矩阵分解模型，query（或user）Embedding是静态已知的，并且系统可以简单地从Embedding矩阵中查找到。
- 对于DNN模型，系统将在服务时间内计算特征向量 [公式] 通过网络后对应的Embedding [公式] 。
有了query Embedding $q$ 后，在Embedding空间中搜索最接近 [$q$ 的item Embedding $V_{j}$ 。 这是一个最近邻问题。 例如，可以根据相似度 $s\left(q, V_{j}\right)$ 得分返回前k个item。

该方法同样可以用于相关item推荐。 例如，当用户观看视频时，系统可以先查找该item对应的Embedding，然后在Embedding空间中查找距离最近的item $V_{j}$ 。

## 大规模检索
为了计算Embedding空间中最接近的top-K个item，系统可以详尽地对计算每个潜在候选者的评分。 但对于大的语料库，详尽的评分可能会很耗时，可以使用以下两种策略之一来提高其效率：

如果query Embedding是静态已知的，则系统可以脱机计算详尽的评分，预先计算并存储每个query的最佳候选item列表。 这是相关item推荐的常见做法。
使用**近似**最近邻。

## 排序
在生成候选对象之后，另一个模型会对生成的候选对象进行打分和排序，得到最后要推送的item列表。 推荐系统可能具有使用不同来源的多个召回队列，例如：

- 矩阵分解模型的相关item。
- 个性化的用户item。
- “本地”与“非本地”项目； 也就是说，要考虑地理信息。
- 热门或流行item。
- 社交网络； 也就是朋友喜欢或推荐的item。

系统将这些不同的来源组合成一个通用的候选库，然后由单个模型对其进行打分并根据该分数进行排名。 例如，系统可以根据以下特征训练模型以预测用户观看视频的概率：

- 查询特征（例如，用户观看记录，语言，国家/地区，时间）
- 视频特征（例如标题，标签，视频Embedding）

然后，系统可以根据模型的预测对候选库中的视频进行排序。

### 为什么不使用召回阶段的得分进行排序，而要重新计算分数？
由于召回阶段会计算分数（例如Embedding空间中的相似性得分），因此您可能会尝试使用此得分进行排序。 但是，出于以下原因，应避免这种做法：

- 一些系统依赖多个召回队列。 这些不同召回队列的得分不具有可比性。
- 由于候选池较小，因此系统可以负担得起更多特征和更复杂的精排模型（可以更好地捕获上下文）。
**选择排序模型的目标函数**
目标函数的选择会极大地影响item的排序结果，并最终影响推荐的质量。

常用的优化目标有以下几种：

**最大化点击率：**如果目标函数只针对点击进行优化，则系统可能会推荐诱导用户点击的视频。 该目标函数可以提高用户点击，但不能带来良好的用户体验。 用户的兴趣可能会很快消失。

**延长观看时间：**如果目标函数针对观看时间进行优化，则系统可能会推荐较长的视频，这可能会导致不良的用户体验。 多个短视频的观看时长和一个长视频的观看时长一样是一样的。

**增加多样性并最大化观看时间：**推荐较短的，但更可能吸引用户的视频。

### 打分的位置偏差
与在屏幕上方显示的item相比，在屏幕下方显示的item被点击的可能性较小。 但是，在对视频打分时，系统通常不知道最终将显示该视频的链接在屏幕上的哪个位置。 对所有可能的位置进行打分太耗时了。 即使对多个位置打分是可行的，系统仍可能无法在多个排序得分中保持一致性。

解决方案

创建与位置无关的排序。
对所有候选item进行排序，假设他们都在屏幕的顶部。

### 重排
在推荐系统的最后阶段，系统对候选item重新排序，以考虑其他因素或约束。 一种重新排序的方法是使用过滤器来删除一些候选item。

示例：可以通过执行以下操作来对视频推荐结果进行重新排名：
训练一个单独的模型来检测视频是否为诱惑点击的钓鱼视频。
在候选集上运行此模型。
在候选集中删除模型判断结果为诱惑点击的视频。
另一种重排方法是转换排序阶段返回的分数。

示例：系统根据以下函数修改得分来重新对视频进行排序：
影片出品时间（也许是在宣传新内容）
影片长度
下面简单介绍下时效性，多样性和公平性。 这些都是可以帮助改善推荐系统的重要因素。 其中一些因素通常需要修改流程的不同阶段。 每个部分均提供您可以单独或共同应用的解决方案。

### 时效性
大多数推荐系统旨在融合最新的使用信息，例如当前用户历史记录和最新item。使模型保持最新状态有助于模型给出更好的推荐。

**解决方案：**

尽可能频繁地重新训练模型以学习最新的训练数据。建议使用在线学习或增量学习等相关技术，以便模型不必从头开始重新学习。增量学习可以大大减少训练时间。例如，在矩阵分解中，加载先前计算出的item Embedding进行更新计算。
创建一个“平均”用户来代表矩阵分解模型中的新用户。不需要为每个用户使用相同的Embedding，可以根据用户特征对用户进行聚类。
使用诸如DNN模型或双塔模型。由于该模型将特征向量作为输入，因此可以在执行在训练数据中未出现的query或item。
添加item年龄相关信息作为特征。例如，可以将视频发布了多长时间或上次观看的时间添加为特征。

### 多样性
如果系统始终推荐与query Embedding “最接近”的item，则候选item往往彼此非常相似。 多样性的缺乏会导致无聊的用户体验。 例如，如果仅推荐与用户当前正在观看的视频非常相似的视频，那么用户可能会很快失去兴趣。

**解决方案**

- 使用不同的来源训练多个召回队列。
- 使用不同的目标函数训练多个排序模型。
- 根据类别或其他元数据对item重新排序，以确保多样性。

### 公平性
模型应公平对待所有用户。 因此，请确保模型没有从训练数据中学习到无意识的偏见。

**解决方案**

- 在设计和开发中融入不同的角度。
- 在综合数据集上训练ML模型。 当数据太稀疏时（例如，某些类别的代表性不足时），添加辅助数据。
- 跟踪每个用户统计指标（例如，准确性和绝对误差）以观察偏差。
- 为特定群体训练单独的模型。
