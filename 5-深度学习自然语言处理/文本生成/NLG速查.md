# NLG速查
[NLG](https://easyai.tech/ai-definition/nlg/) 是为了跨越人类和机器之间的沟通鸿沟，将非语言格式的数据转换成人类可以理解的语言格式，如文章、报告等。

以智能音箱为例，当用户说“几点了？”，首先需要利用 NLU 技术判断用户意图，理解用户想要什么，然后利用 NLG 技术说出“现在是6点50分”。

NLG 是为了跨越人类和机器之间的沟通鸿沟，将非语言格式的数据转换成人类可以理解的语言格式，如文章、报告等。

自然语言生成 – NLG 有2种方式：

1. text – to – text：文本到语言的生成
2. data – to – text ：数据到语言的生成

## NLG的3个Level

**简单的数据合并：**自然语言处理的简化形式，这将允许将数据转换为文本（通过类似Excel的函数）。为了关联，以[邮件合并](https://baike.baidu.com/item/邮件合并/7804213?fr=aladdin)（MS Word mailmerge）为例，其中间隙填充了一些数据，这些数据是从另一个源（例如MS Excel中的表格）中检索的。

**模板化的 NLG** ：这种形式的NLG使用模板驱动模式来显示输出。以足球比赛得分板为例。数据动态地保持更改，并由预定义的业务规则集（如if / else循环语句）生成。

**高级 NLG** ：这种形式的自然语言生成就像人类一样。它理解意图，添加智能，考虑上下文，并将结果呈现在用户可以轻松阅读和理解的富有洞察力的叙述中。

## **NLG 的6个步骤**

**第一步：内容确定 – Content Determination**

作为第一步，NLG 系统需要决定哪些信息应该包含在正在构建的文本中，哪些不应该包含。通常数据中包含的信息比最终传达的信息要多。

**第二步：文本结构 – Text Structuring**

确定需要传达哪些信息后，NLG 系统需要合理的组织文本的顺序。例如在报道一场篮球比赛时，会优先表达「什么时间」「什么地点」「哪2支球队」，然后再表达「比赛的概况」，最后表达「比赛的结局」。

**第三步：句子聚合 – Sentence Aggregation**

不是每一条信息都需要一个独立的句子来表达，将多个信息合并到一个句子里表达可能会更加流畅，也更易于阅读。

**第四步：语法化 – Lexicalisation**

当每一句的内容确定下来后，就可以将这些信息组织成自然语言了。这个步骤会在各种信息之间加一些连接词，看起来更像是一个完整的句子。

**第五步：参考表达式生成 – Referring Expression Generation|REG**

这个步骤跟语法化很相似，都是选择一些单词和短语来构成一个完整的句子。不过他跟语法化的本质区别在于“REG需要识别出内容的领域，然后使用该领域（而不是其他领域）的词汇”。

**第六步：语言实现 – Linguistic Realisation**

最后，当所有相关的单词和短语都已经确定时，需要将它们组合起来形成一个结构良好的完整句子。

## NLG 的3种典型应用

NLG 的不管如何应用，大部分都是下面的3种目的：

1. 能够大规模的产生个性化内容
2. 帮助人类洞察数据，让数据更容易理解
3. 加速内容生产

**自动写新闻**

某些领域的新闻是有比较明显的规则的，比如体育新闻。目前很多新闻已经借助 NLG 来完成了。

**聊天机器人**

大家了解聊天机器人都是从 Siri 开始的，最近几年又出现了智能音箱的热潮。

除了大家日常生活中很熟悉的领域，客服工作也正在被机器人替代，甚至一些电话客服也是机器人。

**BI 的解读和报告生成**

几乎各行各业都有自己的数据统计和分析工具。这些工具可以产生各式各样的图表，但是输出结论和观点还是需要依赖人。NLG 的一个很重要的应用就是解读这些数据，自动的输出结论和观点。（如下图所示）

## NLG演变和处理流程

为了模仿人类的言语，NLG系统使用了不同的方法和技巧，以根据听众，叙述的上下文和目的来适应其写作风格，语调和结构。[Reiter和Dale](https://pdfs.semanticscholar.org/728e/18fbf00f5a80e9a070db4f4416d66c7b28f4.pdf)在2000年通过流水线化NLG架构区分了NLG流程的三个阶段：

为了模仿人类的言语，NLG系统使用了不同的方法和技巧，以根据听众，叙述的上下文和目的来适应其写作风格，语调和结构。[Reiter和Dale](https://pdfs.semanticscholar.org/728e/18fbf00f5a80e9a070db4f4416d66c7b28f4.pdf)在2000年通过流水线化NLG架构区分了NLG流程的三个阶段：

1. **Document planning**：确定要说的内容，并创建概述要呈现的信息结构的抽象文件。
2. **Microplanning**：生成引用表达，单词选择和聚合以充实文档规范。
3. **Realisation**：使用有关语法，形态等的领域知识，将抽象文档规范转换为真实文本。

语言生成有两种主要方法：使用模板和动态创建文档。虽然只有后者被认为是“真实的” NLG，但从基本的简单模板到最新技术，还有很长的，多阶段的方法，每种新方法都扩展了功能并增加了语言能力：

### 简单的填充方法

最古老的方法之一是简单的间隙模板系统。在具有预定义结构的文本中，仅需要填充少量数据，该方法可以使用从电子表格行，数据库表条目等中检索到的数据自动填补这种空白。原则上，您可以更改某些方面文字：例如，您可以决定是拼写数字还是保留数字，此方法的使用受到很大限制，不被视为“真实”的NLG。

### **脚本或产生规则的文本**

通过脚本语言或使用业务规则，通过通用编程结构扩展了基本的填充系统。脚本方法（例如[使用Web模板语言](https://en.wikipedia.org/wiki/Web_template_system)）将模板嵌入通用脚本语言中，因此它允许复杂的条件，循环，对代码库的访问等。业务规则方法，大多数[文档编写](https://en.wikipedia.org/wiki/Document_composition)工具都采用，工作方式相似，但着重于编写业务规则而不是脚本。尽管这种系统比直接填充间隙更强大，但它们仍缺乏语言功能，并且无法可靠地生成复杂的高质量文本。

### 字级语法功能

基于模板的系统的逻辑开发是添加单词级语法功能来处理形态，形态语音和正字法以及处理可能的异常。这些功能使生成语法正确的文本和编写复杂的模板系统变得更加容易

### 动态句子生成

最后，从基于模板的方法迈向动态NLG，该方法从要由句子和/或其所需语言结构传达的含义的表示中动态创建句子。动态创建意味着在异常情况下系统可以做明智的事情，而无需开发人员为每种边界情况显式编写代码。它还允许系统以多种方式在语言上“优化”句子，包括引用，聚合，排序和连接词。

### 动态文件创建

尽管动态句子的生成在某个“微观层次”上起作用，但是“宏写作”任务会生成一个文档，该文档对其读者而言是相关且有用的，并且其结构也很合理。如何完成取决于文本的目标。例如，一篇有说服力的著作可能基于论证和行为改变的模型来模仿人类的言论。总结用于商业智能的数据的文本可能基于对影响决策的关键因素的分析。

## **NLG模型**

即使在NLG从模板转换为动态生成句子之后，仍花费了多年的实验技术才能获得令人满意的结果。作为NLP（更广泛地说，是AI）的一部分，自然语言生成依赖于许多算法，这些算法可以解决创建类似人的文本的某些问题

### 马尔可夫链

马尔可夫链是最早用于语言生成的算法之一。该模型通过使用当前单词并考虑每个唯一单词之间的关系来计算下一个单词的概率，从而预测句子中的下一个单词。实际上，您在智能手机键盘的早期版本中经常看到它们，它们被用来为句子中的下一个单词生成建议。

### 递归神经网络（RNN）

神经网络是试图模仿人脑操作的模型。RNN通过前馈网络传递序列的每个项目，并将模型的输出用作序列中下一个项目的输入，从而可以存储上一步中的信息。在每次迭代中，模型将遇到的先前单词存储在其内存中，并计算下一个单词的概率。对于字典中的每个单词，模型都会根据前一个单词分配一个概率，选择概率最高的单词并将其存储在内存中。RNN的“内存”使该模型非常适合语言生成，因为它可以随时记住对话的背景。但是，随着序列长度的增加，RNN无法存储在句子中远程遇到的单词，并且仅基于最新单词进行预测。由于此限制，RNN无法产生连贯的长句子。

### LSTM

为了解决远程依赖的问题， 引入了一种称为长短期记忆（LSTM）的RNN变体。尽管与RNN类似，但LSTM模型包括一个四层神经网络。LSTM由四个部分组成：单元，输入门，输出门和遗忘门。这些允许RNN通过调整单元的信息流在任何时间间隔记住或忘记单词。当遇到句点时，“遗忘之门”意识到句子的上下文可能会更改，因此可以忽略当前的单元状态信息。这允许网络选择性地仅跟踪相关信息，同时还使消失的梯度问题最小化，从而使模型可以在更长的时间内记住信息。

尽管如此，由于LSTM存储器从前一单元到当前单元的内在复杂的顺序路径，其容量仍被限制为数百个字。相同的复杂性导致较高的计算要求，这使得LSTM难以训练或并行化。

### Transformer

相对较新的模型在2017年Google论文“注意力全能”中首次提出，该论文提出了一种称为“自我注意力机制”的新方法。该Transformer包含一堆用于处理任何长度的输入的编码器和另一组解码器输出生成的句子。与LSTM相比，Transformer仅执行少量恒定的步骤，同时应用了一种自动关注机制，可以直接模拟句子中所有单词之间的关系。与以前的模型不同，Transformer在上下文中使用所有单词的表示形式，而不必将所有信息压缩为单个固定长度的表示形式，从而使系统能够处理更长的句子而不会激增计算需求。

用于生成语言的Transformer最著名的例子之一就是他们的GPT-2语言模型OpenAI。该模型通过关注模型中先前看到的与预测下一个单词相关的单词来学习预测句子中的下一个单词。Google最近更新了一次升级，变形双向编码器表示（BERT）为各种NLP任务提供了最先进的结果。

## NLG工具

您会看到自然语言生成是一项复杂的任务，需要考虑语言的多个方面，包括其结构，语法，单词用法和感知。幸运的是，由于市场提供了多种商用和开源工具，您可能不会从头开始构建整个NLG系统。

### 商用NLG工具

Arria NLG PLC被认为是NLG技术和工具的全球领导者之一，可以拥有最先进的NLG引擎和NLG叙述所产生的报告。该公司拥有可通过Arria NLG平台使用的NLG专利技术。

AX语义：提供超过100种语言的电子商务，新闻和数据报告（例如BI或财务报告）NLG服务。这是一款对开发人员友好的产品，使用AI和机器学习来训练平台的NLP引擎。

Yseop以其跨移动，在线或面对面平台的智能客户体验而闻名。从NLG的角度来看，它提供了可在本地，在云中或作为服务使用的Compose，并提供了Savvy（Excel和其他分析平台的插件）。Narrative Science的Quill是由高级NLG支持的NLG平台。Quill通过开发故事，分析故事并从其中提取所需的数据量，将数据转换为人类智能的叙述。

Automated Insights的Wordsmith是NLG引擎，主要在基于模板的高级方法领域中工作。它允许用户将数据转换为任何格式或比例的文本。Wordsmith还为数据转换提供了许多语言选项。

### 开源NLG工具

Simplenlg可能是使用最广泛的开源实现器，尤其是系统构建者。它是Arria的创始人编写的NLG开源Java API。它具有最少的功能，但也最易于使用且记录最全。

NaturalOWL是一个开源工具包，可用于生成OWL类和个人的描述，从而无需进行大量编程即可将NLG框架配置为满足特定需求。

结论

随着分析平台试图使数据分析民主化并帮助任何人理解其数据，NLG功能已成为事实上的选择。贴近人类的叙述会自动解释洞察力，否则这些洞察力可能会通过自然语言在表格，图表和图形中丢失，并在整个数据发现过程中充当同伴。此外，NLG与NLP的结合是聊天机器人以及其他自动聊天和助手的核心，可为我们提供日常支持。

随着NLG的不断发展，它将变得更加多样化，并将以许多SciFi作家梦books以求的自然方式在我们与计算机之间提供有效的通信。