# 关系抽取
[toc]

定义：固定关系类别集合的关系抽取。
 
##  经典模型
2019 年，[45] 最早将 BERT 应用在关系抽取中，提出了基于 BERT 的关系抽取 R-BERT 模型，通过将一个句子输入到 BERT，并将 BERT 得到的结果输入到全连接层进行多分类，完成关系抽取任务，这个方法在当时取得了超过所有基于深度学习的关系抽取的效果。

[46] 提出 EPGNN 模型（下图），其结合用 BERT 模型提取的句子特征与用图神经网络提取的实体对在知识图谱中的子图的拓扑特征，以进行关系抽取。

![](https://pic4.zhimg.com/v2-985c816e3444fb8f575ae38d4a41df13_r.jpg)

## 远程监督模型
使用远程监督的关系抽取方法面临两个主要问题：

* 无法建模重叠关系：两个实体之间可能存在多个不同的关系，例如（马云，建立，阿里巴巴）和（马云， CEO，阿里巴巴），因此无法确定知识图谱中实体间的哪个关系应该是当前句子需要抽取的关系。

* 噪声（错误）标签：知识图谱中的三元组对有的句子中的实体对提供的关系标签是错误的，这给模型的训练带来了混淆和错误。


### （1）多实例多标签学习（MIML）

为了解决重叠关系的问题，可以将多实例多标签学习应用于关系抽取任务中。单实例学习模型是从一个句子中预测一个关系类别，而多实例多标签学习方法放宽了这一条件，其从一个句子袋中预测其包含的多个关系类别。

#### （2）引入外部知识的方法
以往的研究将不同的关系之间是独立的，但其实关系集自带结构化的高层语义信息，例如在 Freebase 知识图谱中，关系是用层次结构来表示的，每个关系的最高层表示一般性的关系类型。因此可以从关系层次来捕捉不同关系之间的语义相关性。

基于这一特性，[54] 利用关系的层次结构知识，设计了层次注意力机制，在每个句子袋中关注关系之间的相关性信息，实现从粗到细的实例选择，提升远程监督的关系抽取效果。[55] 将 GCN 用于知识图谱嵌入中得到关系的嵌入表示，并提出了一种由粗到细的知识感知注意力机制，将关联的知识集成到关系抽取模型中。


### 实体关系联合抽取

以上介绍的关系抽取方法都需要首先利用命名实体识别技术确定实体提及及其实体类型，再接着便应用关系抽取技术。这种 Pipeline 的方法容易造成误差传播，也就是如果命名实体识别出现误差，在关系抽取阶段会将这一误差放大进而影响关系抽取的效果。采用实体关系联合抽取的方法可以有效避免这种误差传播。同时，**实体识别和关系抽取的目的都是需要自动构建三元组知识，因此这两个任务本来就应是一体的。**

# 挑战
## 4.1 文档级信息抽取难题
### （1）文档结构抽取
在很多垂直行业中，如例图所示的半结构化文档大量存在。如何很好的按照文档内容本身的层次化结构进行数据解析，进而针对其层级结构来归纳整理知识图谱 schema 是当下面临的新的巨大挑战。行业文档的格式多样，有 pdf，word，txt 等多种格式，pdf 格式中又分为标准 pdf，可搜索 pdf 和扫描版 pdf，word 文档的版本也是不尽相同。
### （2）给定schema的信息抽取
在知识图谱 schema 给定的前提下，从此类文档中进行特定信息的抽取，比如抽取保险的投保年龄。由于文档格式和行业表述的多样性以及文档内的交叉引用，使得从文档中直接抽取此类信息变得十分困难，比如第一份文档中的“投保范围”对应投保年龄，第二份文档中的“投保年龄”的真实内容引用了文档 10.1 节的内容。这些需要文档级的语义理解能力和逻辑推理能力，才能很好的进行此类信息抽取。

![](https://pic3.zhimg.com/v2-7999386b80d84e9997f678aaf68ba822_r.jpg)

### 长结构化语言模型

只有在文档的 segment 的表示中融合文档的整体信息，才能做好以文档基础的信息抽取任务。因此，在前述文档得到有效结构化抽取的前提下，如何编码和表示此类结构化数据的宏观和局部信息，也我们面临的第二大挑战。

最近出现的用于编码长句子（1w 字符- 10w 字符级别）的语言模型或许能有效解决上述挑战。具体的，ETC 模型[72]（见下图）利用 Global-local 的 Attention 机制实现了对于长且结构化语句的预训练表示，并在基于网页的层次结构数据的关键短语抽取上验证了其有效性。但是 ETC[72]在多层级结构的语句的编码上仍然没有得到很好的设计，而且 Global-local 的稀疏 Attention 机制也面临信息损失的缺陷。

