# 知识图谱新研究：DrKIT——虚拟知识库上的可微推断，比基于BERT的方法快10倍！
[参考网址](https://mp.weixin.qq.com/s?__biz=MzA5ODEzMjIyMA==&mid=2247501050&idx=1&sn=4a929539481df8786510c3b59eb916a8&chksm=9094cd69a7e3447fe2ee7eec288cf05706b5d89c740c03497aa2ac62b59154e1cce8854abc97&scene=0&xtrack=1)

来自CMU和Google的研究者提出了一种新的将语料库作为虚拟知识库（Virtual Knowledge Base，KB）来回答复杂多跳问题的方法，其可以遍历文本数据，并遵循语料库中各个实体的关系路径，并基于评分的方法，实现了整个系统端到端的训练。实验结果证明此模型可以快速地实现更好的性能。

## 背景
大型的知识库（KBs）可以组织实体中蕴含的信息，并可以简化内容推理的过程，比如Freebase和WikiData。我们可以举例说明，如果有个类似“Gratefu Dead的主唱什么时候出生？”的查询，我们可以将”Grateful Dead“定义为一个实体，定义“主唱”和“出生日期”为可以提取出结果的关系，如果这个信息在知识库中出现，那我们就可以得到问题的答案。

然而，不幸的是，知识库常常是不完整的。虽然关系提取方法可以运用在流行知识库中，但是这一过程在本质上却容易出错，并且是昂贵和缓慢的。

开放领域QA的进展，使得研究者提出了一种替代的方法：与表示关系提取相反的是，通过回答来自于语料库的跨度查询，我们可以将大语料库视为一个虚拟知识图谱。这可以保证事实信息可以在关系提取过程中得到保留。然而，这一方法同样遇到了挑战。这个挑战是，QA模型将每个文档编码为依赖于查询的模式，这使得即使在使用现代硬件设备的情况下，使用QA模型来回答问题依然更加昂贵的。针对复杂问题来说，QA的大量耗费则更是一个的问题（比如前文的例子）。如果“Gratefu Dead的主唱什么时候出生？“这个问题出现的文段和”Jerry Garcia出生在1942年“在语料库中相距很远的距离，那么系统就很难获取并且依靠一个单项文本就去找到答案。更概括地去说，涉及到实体集或者关系集的复杂的问题，可能需要从多个文档中聚合信息，而这个过程是很昂贵的。

研究者为了实现更加有效率的QA，也做出了一些改进工作，比如Seo等人提出的短语索引QA，在此方法中，多语料库之间的跨度和独立于问题的语境表示相关，并通过索引，来实现快速获取功能。研究者将自然语言问题转换为向量来得到问题的答案，而这个向量被用来执行针对索引的最大内部乘积搜索（Miximum Inner Product Search, MIPS)。而近似算法（Shrivastava&Li，2014)的使用则可以保证这一过程的效率。然而，因为在构造过程中，索引中存储的信息关于的是一次跨度中的局部语境，而此局部语境只能在在阅读单个文段之后就能获取其答案的问题中使用，因此，这一过程无法直接被用来回答复杂查询。

本文强调了基于短语检索问答机制的局限。同时，研究人员提出了一种针对在大型文本语料库的复杂问答（QA）的，高效的，端到端的可微网络，而此语料库中则通过独立于查询的原则进行编码。更具体一点，我们考虑“多跳”复杂问题，这一复杂问题可以通过重复执行下面操作的近似版本来回答：
![](https://mmbiz.qpic.cn/mmbiz_png/cNFA8C0uVPsRxjLoI9kicEIaNFicFuKRWpue0t6MJvgj4HfdeL38PdiacPpcXHsudqzPebTCwvf0HSLlTI8CF2H5g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

其中，X是实体集，R为关系集。

在过去的工作中，此操作的近似可微版本被用来回答针对明确的KB的多跳问题。在这里，我们提出了一个更强大的神经模块，这个神经模块的操作主要针对索引语料库（一个虚拟KB），并和前述操作类似。在我们的模块中，输入X是一个有权重的实体集的系数向量，关系R则是一个稠密特征向量，例如，在由一个自然语言查询的神经网络生成的向量。研究人员用X和R来构造一个MIPS查询，此查询可以用来从索引中检索出top-K跨度。而输出Y是另外一个稀疏向量，代表着带权实体集，并由在top-K跨度上的实体提及（Entity Mentions）聚合而来。本文第二部分的第三块主要讨论了索引的预训练机制。

针对多条查询，输出实体Y可以作为下一次迭代的输入，被循环利用到相同的模块中。实体Y是可以微分的，这可以保证实现端到端学习过程。

我们主要讨论基于稀疏矩阵向量乘积的实现过程，这一过程的运行时间和记忆只依赖于从索引中检索到的跨度K的数量。这一点，对于扩展到大型语料库非常关键，并直接实现了在超越最新多跳开放领域QA系统15倍的加速推断过程。

本文将这一新系统称为DrKIT（提取自Differentiable Reasoning over a Knowledge base of Indexed Text)。研究者在针对复杂问题回答的MetaQA基准上进行了DrKIT的测试，结果展现了，相对于先前基于文本的系统，此方法在两跳问题上提高了5个百分点的性能，在三跳问题上提高了9个百分点的性能，从而将基于文本和基于知识库两种系统的差距分别降低了30%和70%。

同时，本文还将DrKIT在Wikipedia上的多跳插槽填充新数据集上进行了测试，结果证明，在此任务上，本文的方法可以超过DrQA(Chen 等人，2017)和PIQA(Seo等人，2019)的表现。

最后，研究者还将DrKIT应用于在HotpotQA数据集（Yang等人，2018)的多跳信息检索任务中，结果表明，与基于BERT的重排序方法相比，此模型可以达到10倍的加速效果。

